{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "sys.path.insert(0, 'Tools/')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data_prep import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found files :/57576-0.txt\n",
      "found files :/57573-0.txt\n",
      "found files :/57582-0.txt\n",
      "found files :/57577-0.txt\n",
      "found files :/57574-0.txt\n",
      "found files :/57583-0.txt\n",
      "found files :/57575-0.txt\n",
      "found files :/57580-0.txt\n"
     ]
    }
   ],
   "source": [
    "overview_selected_files(\"Data/\", \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data/57576-0.txt', 'Data/57573-0.txt', 'Data/57582-0.txt', 'Data/57577-0.txt', 'Data/57574-0.txt', 'Data/57583-0.txt', 'Data/57575-0.txt', 'Data/57580-0.txt']\n"
     ]
    }
   ],
   "source": [
    "paths = paths_selected_files(\"Data/\", \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book #0 has a word length of 55775\n",
      "Book #1 has a word length of 788473\n",
      "Book #2 has a word length of 142117\n",
      "Book #3 has a word length of 196653\n",
      "Book #4 has a word length of 265316\n",
      "Book #5 has a word length of 191917\n",
      "Book #6 has a word length of 645779\n",
      "Book #7 has a word length of 623478\n"
     ]
    }
   ],
   "source": [
    "book_list = open_book_list(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare/clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_books = [clean_text(book) for book in book_list]\n",
    "\n",
    "\n",
    "bookstring = \"\"\n",
    "for book in clean_books:\n",
    "    bookstring += book + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2864736/2864736 [00:01<00:00, 1692138.89it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int = {}\n",
    "count = 0\n",
    "for character in bookstring:\n",
    "    if character not in vocab_to_int:\n",
    "        vocab_to_int[character] = count\n",
    "        count += 1\n",
    "\n",
    "    \n",
    "\n",
    "# Add special tokens to vocab_to_int\n",
    "codes = ['<PAD>','<EOS>','<GO>']\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = count\n",
    "    count += 1\n",
    "\n",
    "\n",
    "filter_chars_dict = {}\n",
    "for character in tqdm(bookstring):\n",
    "    if character not in filter_chars_dict:\n",
    "        filter_chars_dict[character] = 1\n",
    "    else:\n",
    "        filter_chars_dict[character] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list = []\n",
    "for char in filter_chars_dict:\n",
    "    if filter_chars_dict[char] < 55:\n",
    "        filter_list.append(char)\n",
    "re.sub(r\"[',\\s]\",\"\",str(filter_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dictionary to convert integers to their respective characters\n",
    "int_to_vocab = {}\n",
    "for character, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d993ac8485a04309a5c79c8ab1602498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9308880cb22849e4978d1a407bb37958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=437), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b80c4be1a444f1a3c7fc9b655f1edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=5317), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faa65ec85e94f5c89ac0d59f95b3fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=1533), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de670c2eebb04157bb106bedd867bf8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=2227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54524e409b3147a7807fcf97c7cf40ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=2247), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7702811ed879444ab039cf37c9ca6f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=2059), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644736ae7d5e4decad1e07e3ac0cf5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=6092), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7047169865ce4b179e9d0cfcf202a63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', max=4306), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 24218 sentences.\n"
     ]
    }
   ],
   "source": [
    "# Split the text from the books into sentences.\n",
    "sentences = []\n",
    "for book in tqdm_notebook(clean_books, desc=\"1st loop\"):\n",
    "    for sentence in tqdm_notebook(book.split('. '), desc = \"2nd loop\", leave=False): #TODO: maybe split on ! ? and .?\n",
    "        sentences.append(sentence + '.')\n",
    "print(\"There are {} sentences.\".format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sentences = []\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    int_sentence = []\n",
    "    for character in sentence:\n",
    "        int_sentence.append(vocab_to_int[character])\n",
    "    int_sentences.append(int_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>117.289867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>97.195532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>165.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3370.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             counts\n",
       "count  24218.000000\n",
       "mean     117.289867\n",
       "std       97.195532\n",
       "min        1.000000\n",
       "25%       47.000000\n",
       "50%      104.000000\n",
       "75%      165.750000\n",
       "max     3370.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the length of each sentence\n",
    "lengths = []\n",
    "for sentence in int_sentences:\n",
    "    lengths.append(len(sentence))\n",
    "lengths = pd.DataFrame(lengths, columns=[\"counts\"])\n",
    "\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use 10140 to train and test our model.\n"
     ]
    }
   ],
   "source": [
    "# Limit the data we will use to train our model\n",
    "max_length = 104\n",
    "min_length = 10\n",
    "\n",
    "good_sentences = []\n",
    "\n",
    "for sentence in int_sentences:\n",
    "    if len(sentence) <= max_length and len(sentence) >= min_length:\n",
    "        good_sentences.append(sentence)\n",
    "\n",
    "print(\"We will use {} to train and test our model.\".format(len(good_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.294280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28.317424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             counts\n",
       "count  10140.000000\n",
       "mean      56.294280\n",
       "std       28.317424\n",
       "min       10.000000\n",
       "25%       31.000000\n",
       "50%       57.000000\n",
       "75%       81.000000\n",
       "max      104.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the length of each good sentence\n",
    "lengths = []\n",
    "for sentence in good_sentences:\n",
    "    lengths.append(len(sentence))\n",
    "lengths = pd.DataFrame(lengths, columns=[\"counts\"])\n",
    "\n",
    "lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8619\n",
      "Number of testing sentences: 1521\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sentences\n",
    "training, testing = train_test_split(good_sentences, test_size = 0.15, random_state = 2)\n",
    "\n",
    "print(\"Number of training sentences:\", len(training))\n",
    "print(\"Number of testing sentences:\", len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the sentences by length to reduce padding, which will allow the model to train faster\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(min_length, max_length+1):\n",
    "    for sentence in training:\n",
    "        if len(sentence) == i:\n",
    "            y_train.append(sentence)\n",
    "    for sentence in testing:\n",
    "        if len(sentence) == i:\n",
    "            y_test.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
    "           'n','o','p','q','r','s','t','u','v','w','x','y','z',]\n",
    "\n",
    "def noise_maker(sentence, threshold):\n",
    "    '''Relocate, remove, or add characters to create spelling mistakes'''\n",
    "    \n",
    "    noisy_sentence = []\n",
    "    i = 0\n",
    "    while i < len(sentence):\n",
    "        random = np.random.uniform(0,1,1)\n",
    "        # Most characters will be correct since the threshold value is high\n",
    "        if random < threshold:\n",
    "            noisy_sentence.append(sentence[i])\n",
    "        else:\n",
    "            new_random = np.random.uniform(0,1,1)\n",
    "            # ~33% chance characters will swap locations\n",
    "            if new_random > 0.67:\n",
    "                if i == (len(sentence) - 1):\n",
    "                    # If last character in sentence, it will not be typed\n",
    "                    continue\n",
    "                else:\n",
    "                    # if any other character, swap order with following character\n",
    "                    noisy_sentence.append(sentence[i+1])\n",
    "                    noisy_sentence.append(sentence[i])\n",
    "                    i += 1\n",
    "            # ~33% chance an extra lower case letter will be added to the sentence\n",
    "            elif new_random < 0.33:\n",
    "                random_letter = np.random.choice(letters, 1)[0]\n",
    "                noisy_sentence.append(vocab_to_int[random_letter])\n",
    "                noisy_sentence.append(sentence[i])\n",
    "            # ~33% chance a character will not be typed\n",
    "            else:\n",
    "                pass     \n",
    "        i += 1\n",
    "    return noisy_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 0, 1, 2, 3, 31, 0, 22, 60, 35]\n",
      "[26, 0, 1, 2, 3, 31, 0, 22, 60, 35]\n",
      "\n",
      "[41, 3, 9, 11, 29, 5, 14, 0, 14, 35]\n",
      "[41, 3, 9, 11, 29, 5, 14, 0, 14, 35]\n",
      "\n",
      "[62, 39, 14, 21, 11, 5, 29, 0, 54, 35]\n",
      "[62, 39, 14, 21, 11, 5, 29, 0, 54, 35]\n",
      "\n",
      "[53, 55, 38, 38, 49, 20, 26, 0, 53, 35]\n",
      "[53, 55, 38, 38, 49, 20, 3, 26, 0, 53, 35]\n",
      "\n",
      "[15, 18, 18, 22, 10, 12, 7, 3, 10, 35]\n",
      "[15, 18, 18, 22, 10, 12, 7, 3, 10, 35]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check to ensure noise_maker is making mistakes correctly.\n",
    "threshold = 0.9\n",
    "for sentence in y_train[:5]:\n",
    "    print(sentence)\n",
    "    print(noise_maker(sentence, threshold))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for sentence in y_train:\n",
    "    x_train.append(noise_maker(sentence, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for sentence in y_test:\n",
    "    x_test.append(noise_maker(sentence, threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(x_test,\"Data/\",\"x_test\")\n",
    "save_pickle(x_train,\"Data/\",\"x_train\")\n",
    "save_pickle(y_test,\"Data/\",\"y_test\")\n",
    "save_pickle(y_train,\"Data/\",\"y_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
